{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook performs analysis on datasets with zip codes using Pandas, bokeh, and scipy (kmeans2)\n",
    "The data I used was about 2800 rows; the format was price data in the format \"ID, zip, Price\" as the column headers\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bokeh.charts import Bar, output_notebook, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "path = 'data/workbook.csv'\n",
    "zip_count = pd.read_csv(path)\n",
    "zip_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count them up and graph them; here I only graph the top 10, using bokeh\n",
    "zip_count['ZCOUNT'] = zip_count.groupby('zip')['zip'].transform('count')\n",
    "zip_count = zip_count.sort(['ZCOUNT'],ascending=0)\n",
    "zip_count = zip_count.drop_duplicates(subset='zip')\n",
    "zip_count = zip_count.reset_index(drop=True)\n",
    "top_10 = zip_count.ix[0:9,1:4]\n",
    "cat = []\n",
    "zips = top_10['zip']\n",
    "for item in zips:\n",
    "    item = str(item)\n",
    "    cat.append(item.zfill(5))\n",
    "TOOLS = \"pan, previewsave, reset\"\n",
    "bar = Bar(top_10['ZCOUNT'], cat, title = 'Zip Code Frequency', tools=TOOLS, xlabel = 'Zip Code', ylabel = 'Frequency', stacked=True)\n",
    "show(bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#next we need to convert the zip codes into lat/longs for further analysis; here I use the google API\n",
    "import requests\n",
    "zip_count['zip'] = zip_count['zip'].astype(str)\n",
    "zip_list = zip_count['zip'].tolist()\n",
    "urlp1 = 'https://maps.googleapis.com/maps/api/geocode/json?address='\n",
    "urlp2 = '&key=YOUR_KEY_HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use results to receive the JSON from google and append it to a list\n",
    "lat = []\n",
    "lng = []\n",
    "for item in zip_list:\n",
    "    results = requests.get(urlp1+str(item)+urlp2).json()\n",
    "    lat.append(float(results[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]))\n",
    "    lng.append(float(results[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]))\n",
    "zip_count['LAT'] = lat\n",
    "zip_count['LNG'] = lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the geo information from google to a csv to ensure we don't loose it\n",
    "zip_count.to_csv('workbook_withgeo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lets do some basic cluster analysis on the lat/longs, using scipy\n",
    "from scipy.cluster.vq import kmeans2\n",
    "\n",
    "conus = zip_count\n",
    "slon = conus['LNG'].tolist()\n",
    "slat = conus['LAT'].tolist()\n",
    "\n",
    "#we extract the values so we can iterate our kmeans function, number is the number of centroids to produce.\n",
    "number = 5\n",
    "myk = conus[['LAT', 'LNG']].values\n",
    "roid = kmeans2(myk, number, iter = 10)\n",
    "\n",
    "#and produce centroids, which we can use later ...\n",
    "\n",
    "centroids = roid[0]\n",
    "rlon = []\n",
    "rlat = []\n",
    "for item in centroids:\n",
    "    rlat.append(item[0])\n",
    "    rlon.append(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Bokeh has a very nice vector map of the continental US - we can use it\n",
    "#it requires downloading the sample data, which you can do per the instructions here: http://bokeh.pydata.org/en/latest/docs/quickstart.html#sample-data\n",
    "from bokeh.sampledata import us_states,us_counties\n",
    "from bokeh.plotting import figure\n",
    "us_states = us_states.data.copy()\n",
    "us_counties = us_counties.data.copy()\n",
    "\n",
    "#I mainly want to look at the continetal US\n",
    "del us_states[\"HI\"]\n",
    "del us_states[\"AK\"]\n",
    "state_xs = [us_states[code][\"lons\"] for code in us_states]\n",
    "state_ys = [us_states[code][\"lats\"] for code in us_states]\n",
    "'''\n",
    "you can add counties by including this code, but it slows the notebook down\n",
    "county_xs=[us_counties[code][\"lons\"] for code in us_counties if us_counties[code][\"state\"] not in [\"ak\", \"hi\", \"pr\", \"gu\", \"vi\", \"mp\", \"as\"]]\n",
    "county_ys=[us_counties[code][\"lats\"] for code in us_counties if us_counties[code][\"state\"] not in [\"ak\", \"hi\", \"pr\", \"gu\", \"vi\", \"mp\", \"as\"]]\n",
    "'''\n",
    "ttext = \"Cluster Analysis using Kmeans2 for Test Data\"\n",
    "TOOLS = \"pan, wheel_zoom,box_zoom,reset,previewsave\"\n",
    "p = figure(plot_width=1100, plot_height=700, toolbar_location = 'left', title=ttext, tools=TOOLS)\n",
    "\n",
    "#here we overlay the scatter plot of our centroids in blue with our zipcodes in red\n",
    "p.scatter(slon,slat, size=4,color='red',alpha=0.7, legend='Locations')\n",
    "p.patches(state_xs, state_ys, fill_alpha=0.0,line_color=\"#884444\", line_width=1)\n",
    "#p.patches(county_xs, county_ys, fill_color='white', fill_alpha=0,line_color=\"gray\", line_width=0.5, line_alpha=0.5)\n",
    "p.scatter(rlon,rlat, size=12,color='blue',alpha=0.7, legend='Centroids')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now, lets put them into a kml so we can view them in google earth:\n",
    "import simplekml\n",
    "import csv\n",
    "inputfile = 'workbook_withgeo.csv' #this is the file we just created to save the lat-long data\n",
    "with open(inputfile, 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader)\n",
    "    for row in csvreader:\n",
    "        pnt = kml.newpoint()\n",
    "        pnt.altitudemode = 'relativeToGround'\n",
    "        #inspect your file to get the values I use below ...\n",
    "        pnt.name = row[1]\n",
    "        #we'll use the price as the height\n",
    "        height = row[3]+'0000'\n",
    "        pnt.description = str('\\n price :'+row[3])\n",
    "        #long, lat\n",
    "        pnt.coords = [(row[6],row[5], height)]\n",
    "        pnt.style.iconstyle.color = simplekml.Color.red\n",
    "        pnt.style.iconstyle.scale = .3\n",
    "        pnt.style.labelstyle.scale = .75\n",
    "\n",
    "kml.save('test.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
